{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bce6f00",
   "metadata": {},
   "source": [
    "# Prompting LLMs for Patient-Oriented Language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870e8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, TextStreamer\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a6cd0",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988313a8-16e0-4bf5-b6df-0164f6079b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"csv\", data_files=\"../../test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677130fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'topic_id', 'statement_medical', 'statement_pol', 'premise', 'NCT_title', 'NCT_id', 'label'],\n",
      "    num_rows: 1578\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nstatements_pol = data['train']['statement_pol']\\nstatements_med = data['train']['statement_med']\\npremises =  data['train']['premise']\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = load_dataset(\"Mathilde/test_data_pol\")\n",
    "subset = data['train']  # TODO changer en test dans le ds original\n",
    "print(subset)\n",
    "\"\"\"\n",
    "statements_pol = data['train']['statement_pol']\n",
    "statements_med = data['train']['statement_med']\n",
    "premises =  data['train']['premise']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb8cac",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "TODO: change the model's path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a6c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/gpfsdswork/dataset/HuggingFace_Models/mistralai/Mixtral-8x7B-Instruct-v0.1\" # \"/gpfsdswork/dataset/HuggingFace_Models/meta-llama/Llama-2-7b-chat-hf\" #\"/lustre/fsn1/projects/rech/hjp/ulj12fo/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff7abc5-fc40-483c-b286-daecabc70a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer, timeout=10.0, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce56a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards:  42%|####2     | 8/19 [00:31<00:43,  3.97s/it]"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_path, load_in_8bit=True, device_map=\"auto\",)  # torch_dtype=torch.float16, low_cpu_mem_usage=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e0770",
   "metadata": {},
   "source": [
    "## Format the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1349c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_text(premise, hypothesis):\n",
    "    # TODO the persona option + the wrapping of the pol + med \"patients with this medical profile...\"\n",
    "    options_prefix = \"Answer in 1 word only with: \\n- \" #\"OPTIONS:\\n- \"\n",
    "    separator = \"\\n- \"\n",
    "    options_ = options_prefix + f\"{separator}\".join([\"Entailment OR\",\"Contradiction\"])  #  \"Neutral\"\n",
    "    return f\"{premise} \\n Question: Imagine that you are a doctor reviewing patients profiles to enroll them for a clinical trial. Does the previous eligibility criteria imply that the following patient can participate to the trial?\\n Patient profile:\\n {hypothesis}\\n {options_}\"\n",
    "    #return f\"{premise} \\n Question: Does this imply that {hypothesis}? {options_}\"\n",
    "    # Does the previous eligibility criteria imply that the following patient can participate to the trial?\n",
    "    # return f\"Classification: {premise} \\n Question: Does this imply that {hypothesis}? Entailment or Contradiction?Answer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c16fe5-f49f-4e7f-8973-9d5e01b55b8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#subset[149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307dd6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "# TODO adapt in function of the med or POL (l.5)\n",
    "for instance in subset:\n",
    "    premise = instance['premise']\n",
    "    sentence = f\"Eligibility criteria of the trial are:\\n {premise}\"\n",
    "    input_text = get_input_text(sentence, instance['statement_medical'])\n",
    "    # temp = {\"text\":input_text, \"label\":sample['label']}\n",
    "    temp = {\"text\":input_text, \"label\":0}\n",
    "    print(input_text)\n",
    "    samples.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d400dd37",
   "metadata": {},
   "source": [
    "## Define the chat function\n",
    "\n",
    "TODO: adjust the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1a652-a0fe-484e-8271-4bdcdb359675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(\n",
    "    query: str,\n",
    "    history: Optional[List[Dict]] = None,\n",
    "    temperature: float = 0.7,\n",
    "    top_p: float = 1.0,\n",
    "    top_k: float = 0,\n",
    "    repetition_penalty: float = 1.1,\n",
    "    max_new_tokens: int = 5, # 1024,\n",
    "    **kwargs,\n",
    "):\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": query})\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(history, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "    input_length = input_ids.shape[1]\n",
    "\n",
    "    generated_outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=temperature,\n",
    "            do_sample=temperature > 0.0,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            **kwargs,\n",
    "        ),\n",
    "        streamer=streamer,\n",
    "        return_dict_in_generate=True,\n",
    "    )\n",
    "\n",
    "    generated_tokens = generated_outputs.sequences[0, input_length:]\n",
    "    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    history.append({\"role\": \"assistant\", \"content\": generated_text})\n",
    "\n",
    "    return generated_text, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00aa0f-26c9-488f-ad00-e3c984005e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = chat(samples[54]['text'], history=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972f607-bc87-4314-be7c-2394bdadbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples[52]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce8ee4",
   "metadata": {},
   "source": [
    "## Call the chat function on the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873f800-d556-4b6d-a453-37223706987b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "pred = []\n",
    "#with torch.inference_mode():\n",
    "for sample in tqdm.tqdm(samples):\n",
    "    labels.append(sample[\"label\"])\n",
    "    # input_ids = tokenizer(sample[\"text\"], return_tensors=\"pt\",).input_ids.to(\"cuda\")\n",
    "    # input_ids = tokenizer.apply_chat_template(sample[\"text\"], return_tensors=\"pt\",).to(\"cuda\")\n",
    "    # outputs = model.generate(input_ids, max_new_tokens=20)\n",
    "    response, history = chat(sample['text'], history=None)\n",
    "    pred.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708cd824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = [p[5:][:-4].strip() for p in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c2bd7",
   "metadata": {},
   "source": [
    "## Parse model's output\n",
    "\n",
    "TODO: adapt the pattern in function of the model's output style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4a755-36f2-4e4b-8e1b-64226af0c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"entailment|contradiction|Entailment|Contradiction|entail\"  # |Neutral|neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15599cca-32ff-4583-8b26-ba4aff0a96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to match text with regular expression\n",
    "def match_text_with_regexp(text, pattern):\n",
    "    text = text.strip()\n",
    "    # print(text)\n",
    "    # Compile the regular expression pattern\n",
    "    regexp = re.compile(pattern)\n",
    "    \n",
    "    # Search for a match in the text\n",
    "    match = regexp.search(text)\n",
    "    # print(match)\n",
    "    \n",
    "    if match:\n",
    "        # If a match is found, return the matched text\n",
    "        return match.group()\n",
    "    else:\n",
    "        # If no match is found\n",
    "        return None\n",
    "\n",
    "parsed_preds = []\n",
    "\n",
    "for p in pred:\n",
    "    # text = pred[0]\n",
    "    pattern = \"entailment|contradiction|Entailment|Contradiction|entail|yes|Yes|No|no\"  # |Neutral|neutral\n",
    "    \n",
    "    result = match_text_with_regexp(p, pattern)\n",
    "    \n",
    "    if result:\n",
    "        if result in ['entailment', 'entail', 'yes', 'Yes']:\n",
    "            result = 'Entailment'\n",
    "        elif result in ['contradiction', 'contradicts', 'no', 'No']:\n",
    "            result = 'Contradiction'\n",
    "        #elif result in ['neutral', 'Neutral']:\n",
    "            #result = 'Neutral'\n",
    "        # print(f\"Match found: {result}\")\n",
    "        parsed_preds.append(result) \n",
    "    else:\n",
    "        # print(\"No match found.\")\n",
    "        # if nothing exploitable predicted --> assert \"Neutral\"\n",
    "        parsed_preds.append(\"Contradiction\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5d3c3-c024-4d22-ba7a-a5ff85ff29ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d349880",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(parsed_preds)\n",
    "from collections import Counter\n",
    "Counter(parsed_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14285058",
   "metadata": {},
   "source": [
    "## Save the predictions in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbbb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dict = {}\n",
    "for _id,pred_x in zip(data['train']['id'], parsed_preds):\n",
    "    prediction_dict[str(_id)] = {\"Prediction\":pred_x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317efb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# uuid_list = list(prediction_dict.keys())\n",
    "# results_pred = []\n",
    "# gold_labels = []\n",
    "# for i in range(len(uuid_list)):\n",
    "#     if prediction_dict[uuid_list[i]][\"Prediction\"] in [\"Entailment\", \"Yes\"]:\n",
    "#         results_pred.append(1)\n",
    "#     else:\n",
    "#         results_pred.append(0)\n",
    "#     if data[uuid_list[i]][\"Label\"] in [\"Entailment\", \"No\"]:\n",
    "#         gold_labels.append(1)\n",
    "#     else:\n",
    "#         gold_labels.append(0)\n",
    "# f1_score(gold_labels,results_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfcff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(prediction_dict, open(\"results_mixtral_zs_med_persona.json\",'w'),indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a17ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.3.0_py3.11.5",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.3.0_py3.11.5"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
